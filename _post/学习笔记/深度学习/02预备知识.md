## 张量（Tensor）

### 张量的概念

张量（Tensor）是线性代数中的一个概念，用于描述多维数据的一种数学对象。它是标量、向量和矩阵的广义形式。具体来说：

1. **标量（Scalar）**：是零阶张量，即单一的数值，例如3或π。

2. **向量（Vector）**：是一阶张量，即一组有序数值，可以看作是长度为n的一维数组，例如\([1, 2, 3]\)。

3. **矩阵（Matrix）**：是二阶张量，即一个二维数组，具有行和列，例如  [[1,2,3],[4,5,6]] (一个2x3的矩阵)

4. **高阶张量（Higher-order Tensor）**：是更高维度的数组。例如 一个 2x3x4 的三阶张量，使用三维数组表示。

   ```python
   # 一个 2x3x4 的三阶张量
   [
       [
           [1,2,3,4],
           [2,3,4,5],
           [3,4,5,6]
       ],
       [
           [1,2,3,4],
           [2,3,4,5],
           [3,4,5,6]
       ]
   ]
   
   # 压缩
   [[[1,2,3,4],[2,3,4,5],[3,4,5,6]],[[1,2,3,4],[2,3,4,5],[3,4,5,6]]]
   ```

张量的应用范围非常广泛，在物理学、工程学、计算机科学、机器学习等领域都有重要作用。特别是在机器学习和深度学习中，张量是数据的基本表示形式，许多框架（如TensorFlow、PyTorch）都以张量为核心数据结构进行操作和计算。

### 张量的性质和操作

张量可以通过以下几个方面来描述：

1. **秩（Rank）**：张量的维度数。例如，标量的秩为0，向量的秩为1，矩阵的秩为2，三维数组的秩为3。

2. **形状（Shape）**：描述张量在每个维度上的大小。例如，一个形状为(3, 4)的矩阵表示它有3行4列。

   ```
   注意：当上升为高阶张量时，无法用特定于二维矩阵的概念【行列】进行描述
   ```

3. **元素类型**：张量中的元素可以是整数、浮点数等。

常见的张量操作包括：

- **基本算术运算**：如加法、减法、乘法、除法等。
- **张量变换**：如转置（Transpose）、reshape等。
- **索引和切片**：访问和修改张量的特定部分。
- **广播（Broadcasting）**：一种方便处理不同形状张量之间运算的机制。

通过这些操作，张量能够灵活地表示和处理复杂的数据结构，是现代科学计算和机器学习的基础工具之一。



### PyTorch中的张量

#### torch.arange()函数

`torch.arange()` 是 PyTorch 中用于生成一个`一维张量`（tensor）的函数。它的功能类似于 Python 标准库中的 `range()` 函数，但返回的是一个张量而不是列表。

**基本用法**

`torch.arange()` 函数的基本语法如下：

```python
torch.arange(start=0, end, step=1, *, dtype=None, device=None, requires_grad=False)
```

- `start`：序列开始的数值，默认值是 0。
- `end`：序列结束的数值（不包含该值）。
- `step`：序列中相邻数值之间的步长，默认值是 1。
- `dtype`：结果张量的数据类型。
- `device`：结果张量的设备（如 `cpu` 或 `cuda`）。
- `requires_grad`：如果为 `True`，将记录对张量的操作，用于自动求导。

**案例**

- 创建一个简单的数值序列

  ```python
  import torch
  
  # 从0到9的整数序列
  tensor = torch.arange(10)
  print(tensor)
  
  # 输出
  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
  ```

- 综合案例

  ```python
  import torch
  
  # 创建一个从 -1 到 1，步长为 0.5 的张量，类型为 float32，位于 GPU 上，并且需要梯度（自动求导）
  tensor = torch.arange(-1, 1, 0.5, dtype=torch.float32, device='cuda', requires_grad=True)
  print(tensor)
  
  # 输出
  tensor([-1.0000, -0.5000,  0.0000,  0.5000], device='cuda:0', requires_grad=True)
  ```

#### torch.randn()函数

`torch.randn()` 是 PyTorch 中用于生成服从标准正态分布（又称高斯分布 —— 均值为 0，标准差为 1）的张量的函数。这个函数对于初始化模型参数或创建随机数据非常有用。

**基本用法**

`torch.randn()` 函数的基本语法如下：

```python
torch.randn(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
```

- `size`：张量的形状，可以是一个整数或者一个整数元组。
- `out`：可选，用于指定输出张量。
- `dtype`：张量的数据类型。
- `layout`：张量的布局，默认是 `torch.strided`。
- `device`：张量的设备（如 `cpu` 或 `cuda`）。
- `requires_grad`：如果为 `True`，将记录对张量的操作，用于自动求导。

#### torch.multinomial()函数

`torch.multinomial` 是 PyTorch 中的一个函数，用于从给定的概率分布中进行多项式（多项分布）采样。该函数常用于实现采样操作，尤其是在需要从概率分布中随机选择样本的情境下，如在生成模型和强化学习中。

**函数签名**

```python
torch.multinomial(input, num_samples, replacement=False, *, generator=None, out=None) → LongTensor
```

**参数**

- `input` (Tensor): 包含概率分布的输入张量。必须是1维或2维的，且其中的元素是非负的。
- `num_samples` (int): 需要采样的样本数量。
- `replacement` (bool, optional): 是否有放回地采样。如果为 `True`，表示采样时有放回；如果为 `False`，表示采样时无放回。
- `generator` (torch.Generator, optional): 一个可选的随机数生成器，用于控制采样的随机性。
- `out` (Tensor, optional): 可选的输出张量。

**返回**

返回一个长整型张量，包含从输入概率分布中采样得到的索引。

**使用示例**

```
python复制import torch

# 定义一个概率分布张量
probs = torch.tensor([0.1, 0.3, 0.4, 0.2])

# 无放回地采样3个样本
samples_without_replacement = torch.multinomial(probs, 3, replacement=False)
print(samples_without_replacement)

# 有放回地采样3个样本
samples_with_replacement = torch.multinomial(probs, 3, replacement=True)
print(samples_with_replacement)
```
